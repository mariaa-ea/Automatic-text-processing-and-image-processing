{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUuyLVDZ4s8r"
      },
      "source": [
        "# ЗАДАНИЕ ДЛЯ ПРОГРАММИРУЮЩИХ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwJ5Q6w2IFHA"
      },
      "source": [
        "**Ссылка**, на источник текста:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64uxt-07IEec"
      },
      "source": [
        "DATA_URL = \"http://az.lib.ru/t/tolstoj_a_k/text_0180.shtml\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwrBkeLnHuA1"
      },
      "source": [
        "Устанавливаем библиотеки:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5Fr5swwYfz5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc4dd7a7-1908-4bbc-c2d3-6ecf734a8336"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "!pip install -q git+https://github.com/dvolchek/rnnmorph.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for rnnmorph (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for russian-tagsets (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbxMKqhPH1Dk"
      },
      "source": [
        "Создаём объект морфологического анализатора `RNNMorph`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rnnmorph.predictor import RNNMorphPredictor"
      ],
      "metadata": {
        "id": "rTzmeZ8rcD1W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24zMUhvi99AV"
      },
      "source": [
        "predictor = RNNMorphPredictor(language=\"ru\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59q1L9p0H9K9"
      },
      "source": [
        "Скачиваем текст, по которому будет дано задание, с помощью `urllib`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request"
      ],
      "metadata": {
        "id": "_Cxq0kkQcCF5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uW0fw_h-Pft"
      },
      "source": [
        "opener = urllib.request.URLopener({})\n",
        "resource = opener.open(DATA_URL)\n",
        "raw_text = resource.read().decode(resource.headers.get_content_charset()) # текст с html-тегами"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "-hSPOjDo4sdh",
        "outputId": "5e391381-77cc-4722-f6c7-a75d888b7109"
      },
      "source": [
        "raw_text[:200]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<html>\\r\\n<head>\\r\\n<title>Lib.ru/Классика: Толстой Алексей Константинович. Семья вурдалака</title>\\r\\n</head>\\r\\n\\r\\n<body>\\r\\n\\r\\n\\r\\n<center>\\r\\n\\r\\n<h2><a href=/t/tolstoj_a_k/>Толстой Алексей Константинович</a><br>\\r\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZiLHQNSITAt"
      },
      "source": [
        "Как видно, текст содержит html теги, от которых нужно избавиться. Выбрасываем из текста HTML-теги с помощью библиотеки Beatiful soap:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "frSiIRm3sANV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "We4LkyUMPfuq"
      },
      "source": [
        "soup = BeautifulSoup(raw_text, features=\"html.parser\")\n",
        "\n",
        "# Уничтожим все элементы script и style\n",
        "for script in soup([\"script\", \"style\"]):\n",
        "    script.extract()    # Извлечем\n",
        "\n",
        "# Получим текст\n",
        "cleaned_text = soup.get_text()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "lOD8PJnG4rbl",
        "outputId": "1b030cd7-ae5a-46bc-ab29-c6cdbbab67f6"
      },
      "source": [
        "cleaned_text[:200]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nLib.ru/Классика: Толстой Алексей Константинович. Семья вурдалака\\n\\n\\n\\nТолстой Алексей Константинович\\r\\nСемья вурдалака\\n\\n\\nLib.ru/Классика:\\n\\r\\n\\n\\n[Регистрация]\\n \\n\\r\\n\\r\\n\\r\\n[Найти] \\r\\n[Рейтинги]\\r\\n[Обсуждения]\\r\\n['"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14fYYb5hIpnY"
      },
      "source": [
        "С помощью библиотеки [NLTK](https://nltk.org/) разбиваем текст на предложения и токены."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ho-TvNcScASO",
        "outputId": "6899288f-0cc6-4f7a-828b-7b3295bf1af8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hRNu7jPvN6G_",
        "outputId": "035567e7-324e-4f47-835a-d5c505149854"
      },
      "source": [
        "tokenized_sentences = [word_tokenize(sentence) for sentence in sent_tokenize(cleaned_text)]\n",
        "\"Всего %d предложений\" % len(tokenized_sentences)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Всего 576 предложений'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRU4KEBAIyYT"
      },
      "source": [
        "# Задание 1\n",
        "С помощью метода `str.isalpha` из стандартной библиотеки Python модифицируйте нижеследующий код так, чтобы в predictions остались только буквенные токены."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "cv9VdZCvb8ba"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4U5HH2CDPVUM",
        "outputId": "a5ddfbd8-efac-440a-efdc-7cb2b51fae46"
      },
      "source": [
        "predictions = [[pred.normal_form for pred in sent]\n",
        "               for sent in tqdm(predictor.predict_sentences(sentences=tokenized_sentences), \"sentences\") ]\n",
        "\n",
        "predictions[-11:-10] # Сейчас видно, что токены типа \"точка\", \"запятая\" и т.д. пока присутствуют в предложениях. От них нужно избавиться"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 7s 570ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sentences: 100%|██████████| 576/576 [00:00<00:00, 120266.78it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['другой',\n",
              "  'ребёнок',\n",
              "  'я',\n",
              "  'такой',\n",
              "  'же',\n",
              "  'образ',\n",
              "  'кинуть',\n",
              "  'вслед',\n",
              "  ',',\n",
              "  'но',\n",
              "  'он',\n",
              "  'упасть',\n",
              "  'прямо',\n",
              "  'под',\n",
              "  'копыто',\n",
              "  'лошадь',\n",
              "  'и',\n",
              "  'быть',\n",
              "  'раздавленный',\n",
              "  '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [[pred.normal_form for pred in sent if pred.normal_form.isalpha()]\n",
        "               for sent in tqdm(predictor.predict_sentences(sentences=tokenized_sentences), \"sentences\")]\n",
        "\n",
        "print(predictions[-11:-10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJc3YNRiUMFz",
        "outputId": "58f2cbd9-014c-4199-8e34-9d4f45783055"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 5s 613ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sentences: 100%|██████████| 576/576 [00:00<00:00, 149140.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['другой', 'ребёнок', 'я', 'такой', 'же', 'образ', 'кинуть', 'вслед', 'но', 'он', 'упасть', 'прямо', 'под', 'копыто', 'лошадь', 'и', 'быть', 'раздавленный']]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHGDhxhNJtTz"
      },
      "source": [
        "Проверьте себя. Должны получиться следующие значения:\n",
        "\n",
        "*   Предложений: 577 (возможны расхождения в несколько предложений)\n",
        "*   Токенов: примерно 8621 (возможны расхождения в некоторое количество токенов)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwK_qRbw6sac",
        "outputId": "95e04334-09fa-41d6-a6d4-cdf00d15fe27"
      },
      "source": [
        "len(predictions)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "576"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5jL4sWyKUnO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07754398-0926-4e51-da6e-de8554774cfd"
      },
      "source": [
        "non_uniq_tokens = [word for sentence in predictions for word in sentence]\n",
        "len(non_uniq_tokens)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8619"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg2e-1hAKiT3"
      },
      "source": [
        "Для продолжения работы над заданием числа должны быть близки к указанным."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mci9Nd5hKuJP"
      },
      "source": [
        "# Задание 2\n",
        "\n",
        "Используя `non_uniq_tokens`, стоп-слова для русского языка из библиотеки nltk (`nltk.corpus.stopwords`) и `nltk.FreqDist`, вычислите, **какую долю среди 100 самых частотных** токенов в произведении занимают токены, **не относящиеся** к стоп словам.\n",
        "\n",
        "**Например**, если среди 100 самых частотных слов встречается 25 слов, входящих в стоп лист, значит не входят в стоп лист 75 слов, и их доля составит 0.75.\n",
        "\n",
        "**Не бойтесь использовать документацию NLTK и тьюториалы.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import FreqDist\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC-ujyFysN53",
        "outputId": "233e75a9-9504-4ce4-9bae-e8bf9d459a2d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHbtLqkLKfZC",
        "outputId": "82331287-bb69-4488-fd37-edbd68fc9583"
      },
      "source": [
        "STOPWORDS = set(stopwords.words(\"russian\"))\n",
        "stopwords.words(\"russian\")[:5] # Пример стоп-слов"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['и', 'в', 'во', 'не', 'что']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создадим объект для подсчета частоты встречаемости слов\n",
        "fdist = FreqDist()\n",
        "\n",
        "# Произведем подсчет частоты встречаемости слов в non_uniq_tokens\n",
        "for word in non_uniq_tokens:\n",
        "    fdist[word.lower()] += 1\n",
        "\n",
        "# Сделаем сортировку по убыванию частоты встречаемости\n",
        "sortedDict = sorted(fdist.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Получение 100 самых частотных слов\n",
        "top_100 = [w[0] for w in sortedDict[:100]]\n",
        "print(top_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uikg82jFVNIR",
        "outputId": "4d1becc5-7bb0-4f2e-9619-7757cfd1b617"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['я', 'и', 'он', 'в', 'не', 'что', 'быть', 'на', 'как', 'с', 'мой', 'ты', 'который', 'здёнка', 'а', 'но', 'тот', 'весь', 'же', 'это', 'георгий', 'к', 'у', 'так', 'свой', 'о', 'этот', 'мы', 'за', 'старик', 'уже', 'сказать', 'вы', 'бы', 'то', 'от', 'один', 'себя', 'из', 'когда', 'только', 'да', 'мочь', 'говорить', 'нет', 'по', 'ни', 'знать', 'ребёнок', 'всё', 'тут', 'такой', 'горчить', 'ещё', 'со', 'лицо', 'чтобы', 'отец', 'мальчик', 'глаз', 'кол', 'дом', 'день', 'голос', 'кровь', 'несколько', 'время', 'сам', 'если', 'милостивый', 'государыня', 'пётр', 'увидеть', 'час', 'вот', 'теперь', 'слово', 'рука', 'стать', 'другой', 'сердце', 'ответить', 'вдруг', 'комната', 'окно', 'семья', 'для', 'думать', 'видеть', 'ли', 'ночь', 'дать', 'брат', 'скорый', 'спросить', 'раз', 'милый', 'минута', 'до', 'лишь']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Посчитаем, сколько стоп-слов входят в топ-100\n",
        "k = 0\n",
        "for word in STOPWORDS:\n",
        "    if word in top_100:\n",
        "        k += 1\n",
        "\n",
        "proportion = k / len(top_100)\n",
        "print(proportion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwBMoCzRY4K8",
        "outputId": "278bca65-8bcd-4228-e30b-b781fce8e842"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezdbB95YwtSl"
      },
      "source": [
        "Проверьте себя: должно получиться 0.49 (допустимо небольшое расхождение)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HChyAdk2Ovx1"
      },
      "source": [
        "# Задание 3\n",
        "Вычислите, сколько токенов встречается в тексте **строго больше** 50 раз."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_over_50 = sum(1 for freq in fdist.values() if freq > 50)\n",
        "print(\"Количество токенов, встречающихся более 50 раз:\", count_over_50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgl9uvn8Vl6a",
        "outputId": "e6f4fa25-1352-4ac3-e14c-a3b6d7a7ea62"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество токенов, встречающихся более 50 раз: 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6HZ2w3yxJEh"
      },
      "source": [
        "Проверьте себя: должно получиться значение 22 (возможно небольшое расхождение)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Индивидуальное задание"
      ],
      "metadata": {
        "id": "MwexTqo2aDmI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "По [ссылке](http://az.lib.ru/g/gogolx_n_w/text_0050.shtml) находится произведение русской классики. Ваша задача -- применить RNNMorph, для анализа произведения.\n",
        "\n",
        "1. Найдите количество предложений. Введите целое неотрицательное число (допустимая погрешность: 20 предложений):\n",
        "    ```\n",
        "    934\n",
        "    ```\n",
        "2. Найдите количество токенов, состоящих только из букв. Введите целое неотрицательное число (допустимая погрешность: 50 токенов):\n",
        "    ```\n",
        "    11732\n",
        "    ```\n",
        "3. Какую долю среди 50 самых частотных токенов в произведении занимают слова, не входящие в стоп-лист? Десятичный разделитель точка. Ответ округлите до сотых (допустимая погрешность: 0.1):\n",
        "    ```\n",
        "    0.28\n",
        "    ```\n",
        "4. Сколько токенов встречается в тексте строго больше 100 раз? Введите целое неотрицательное число (допустимая погрешность: 10 токенов):\n",
        "    ```\n",
        "    10\n",
        "    ```\n"
      ],
      "metadata": {
        "id": "nRGNFqQJaH_H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "DM8sbxtBjuT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"http://az.lib.ru/g/gogolx_n_w/text_0050.shtml\""
      ],
      "metadata": {
        "id": "tbOh4DD9cLE9"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = RNNMorphPredictor(language=\"ru\")\n",
        "opener = urllib.request.URLopener({})\n",
        "resource = opener.open(url)\n",
        "raw_text = resource.read().decode(resource.headers.get_content_charset())\n",
        "\n",
        "soup = BeautifulSoup(raw_text, features=\"html.parser\")\n",
        "\n",
        "for script in soup([\"script\", \"style\"]):\n",
        "    script.extract()\n",
        "\n",
        "cleaned_text = soup.get_text()\n",
        "tokenized_sentences = [word_tokenize(sentence) for sentence in sent_tokenize(cleaned_text)]\n",
        "\n",
        "print(\"Всего %d предложений.\" % len(tokenized_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqQPM2uGcJPT",
        "outputId": "d1fb670c-edfc-4b79-d1af-ff9067a02563"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего 934 предложений.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [[pred.normal_form for pred in sent if pred.normal_form.isalpha()]\n",
        "               for sent in tqdm(predictor.predict_sentences(sentences=tokenized_sentences), \"sentences\")]\n",
        "\n",
        "count_alpha_tokens = 0\n",
        "for sent in predictions:\n",
        "    for token in sent:\n",
        "        if token.isalpha():\n",
        "            count_alpha_tokens += 1\n",
        "\n",
        "print(\"\\n\\nКоличество токенов, состоящих только из букв:\", count_alpha_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFUSqL-DiXDQ",
        "outputId": "856bef4d-79ca-4320-e4e5-c63d3e5e0fe8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 8s 447ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sentences: 100%|██████████| 934/934 [00:00<00:00, 113251.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Количество токенов, состоящих только из букв: 11732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "non_uniq_tokens = [word for sentence in predictions for word in sentence]"
      ],
      "metadata": {
        "id": "15-JugxoqyD3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fdist = FreqDist()\n",
        "for word in non_uniq_tokens:\n",
        "    fdist[word.lower()] += 1\n",
        "\n",
        "sortedDict = sorted(fdist.items(), key=lambda x: x[1], reverse=True)\n",
        "top_50 = [w[0] for w in sortedDict[:50]]"
      ],
      "metadata": {
        "id": "FzqrO5fJiGYQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 0\n",
        "for word in STOPWORDS:\n",
        "    if word in top_50:\n",
        "        k += 1\n",
        "\n",
        "proportion = 1 - k / len(top_50)\n",
        "print(proportion)\n",
        "\n",
        "print(\"Доля токенов, не относящихся к стоп-листу, среди 50 самых встречаемых:\", round(proportion, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcbJKnrEiDdi",
        "outputId": "6d442094-0207-4d33-fe1a-d06802185e50"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.28\n",
            "Доля токенов, не относящихся к стоп-листу, среди 50 самых встречаемых: 0.28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_over_100 = sum(1 for freq in fdist.values() if freq > 100)\n",
        "print(\"Количество токенов, встречающихся более 100 раз:\", count_over_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7uR9VXpiA84",
        "outputId": "6c732659-f03a-4942-ffc2-225647bd9614"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество токенов, встречающихся более 100 раз: 10\n"
          ]
        }
      ]
    }
  ]
}