{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLYpSPDlW9LC"
      },
      "source": [
        "## Скачиваем необходимое\n",
        "\n",
        "Сначала нужно средствами NLTK загрузить WordNet.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhTQ6EFXZ5R9",
        "outputId": "96b84d9d-3ab7-4016-f662-82cd2e2107de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIQ4rEytvwLZ"
      },
      "source": [
        "## Готовим данные к работе\n",
        "\n",
        "Затем импортируем данные из подготовленного текстового файла. Файл содержит набор пар слов (только имён существительных), для которых известны экспертные оценки сходства.\n",
        "\n",
        "Строим ассоциативный массив \"пара слов -- оценка близости\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_sTFACx3dAk8"
      },
      "outputs": [],
      "source": [
        "with open(\"wordsim_similarity_goldstandard.txt\", encoding=\"utf-8\") as rf:\n",
        "    triples = [line.strip().split(\"\\t\") for line in rf.readlines()]\n",
        "    score_map = {tuple(triple[:2]): float(triple[2]) for triple in triples}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_8hjsToCmGd"
      },
      "source": [
        "Отметим, что из исходного набора данных мы взяли только экспертные оценки сходства (similarity) и только для существительных. Исходный набор данных доступен по [ссылке](http://alfonseca.org/pubs/ws353simrel.tar.gz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96B0OtKrvtaG"
      },
      "source": [
        "Посмотрим на примеры оценок.\n",
        "\n",
        "У слов может быть по несколько значений, которые различаются в WordNet. Здесь -- ради примера -- мы будем \"жадно\" выбирать первое попавшееся, но далее будем работать с ними иначе.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iXamIiZgf-O",
        "outputId": "343be156-4ca5-48b6-b3f3-ea32b8a89ee8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Words: tiger-cat\n",
            "Ground truth score: 7.35\n",
            "\n",
            "Path: 0.091 \n",
            "wup: 0.545 \n",
            "shortest_path: 10.000\n",
            "\n",
            "Words: tiger-tiger\n",
            "Ground truth score: 10.00\n",
            "\n",
            "Path: 1.000 \n",
            "wup: 0.750 \n",
            "shortest_path: 0.000\n"
          ]
        }
      ],
      "source": [
        "for w_1, w_2 in list(score_map)[:2]:\n",
        "    print(\"\\nWords: %s-%s\\nGround truth score: %.2f\" % (w_1, w_2, score_map[(w_1, w_2)]))\n",
        "\n",
        "    ss_1 = wn.synset(w_1 + \".n.01\")\n",
        "    ss_2 = wn.synset(w_2 + \".n.01\")\n",
        "\n",
        "    print(\"\\nPath: %.3f\" % ss_1.path_similarity(ss_2), end=\" \")\n",
        "    print(\"\\nwup: %.3f\" % ss_1.wup_similarity(ss_2), end=\" \")\n",
        "    print(\"\\nshortest_path: %.3f\" % ss_1.shortest_path_distance(ss_2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHM7tCb0vqNp"
      },
      "source": [
        "Вычисляем для всех пар несколько оценок"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe7Nuglqgnd3",
        "outputId": "4e7d9a74-2491-46b9-8956-acd2cb4a0468"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drink eat error: max() arg is an empty sequence\n",
            "stock live error: max() arg is an empty sequence\n"
          ]
        }
      ],
      "source": [
        "from itertools import product\n",
        "\n",
        "list_pairs = list(score_map)\n",
        "wup_list, true_list, path_list = [], [], []\n",
        "\n",
        "# Для всех пар\n",
        "for w_1, w_2 in list_pairs:\n",
        "\n",
        "    try:\n",
        "        all_w_1 = wn.synsets(w_1, pos=\"n\")\n",
        "        all_w_2 = wn.synsets(w_2, pos=\"n\")\n",
        "\n",
        "        # Добавляем интересующие нас метрики и экспертные оценки\n",
        "        wup = max([item1.wup_similarity(item2) \\\n",
        "                    for item1, item2 in product(all_w_1, all_w_2)])\n",
        "        wup_list.append(wup)\n",
        "\n",
        "        path = max([item1.path_similarity(item2) \\\n",
        "                    for item1, item2 in product(all_w_1, all_w_2)])\n",
        "        path_list.append(path)\n",
        "\n",
        "        true_list.append(score_map[(w_1, w_2)])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(w_1, w_2, \"error:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAjuTLB0fD-I"
      },
      "source": [
        "## Вычисляем ранговую корреляцию Спирмена"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXnCdw8wxcVd",
        "outputId": "2f5fb12f-b898-4ade-c9d8-b839b32c5f6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wup    Spearman R: 0.6438\n",
            "path Spearman R: 0.6176\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import spearmanr\n",
        "\n",
        "coef, p = spearmanr(wup_list, true_list)\n",
        "print(\"wup    Spearman R: %.4f\" % coef)\n",
        "\n",
        "coef, p = spearmanr(path_list, true_list)\n",
        "print(\"path Spearman R: %.4f\" % coef)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Индивидуальное задание"
      ],
      "metadata": {
        "id": "yR8_BbL4DzzX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "По [ссылке](https://courses.openedu.ru/assets/courseware/v1/a6f9fc5c76dbb8d2efd33bd0e1240208/asset-v1:ITMOUniversity+AUTXTIMGPROC+spring_2024_ITMO_mag+type@asset+block/Task_4_sample_9.csv) представлена выборка из датасета WordSim353. Ваша задача, используя тезаурус WordNet, вычислить оценки близости для всех элементов соответствующих синсетов представленных пар слов. В качестве близости двух слов использовать наибольшую близость среди соответствующих элементов рассматриваемых синсетов. В качестве меры близости использовать: близость на основе пути (`path_similarity`), меру Leacock-Chodorow (`lch_similarity`) и меру Wu-Palmer (`wup_similarity`). Вычислить коэффициент ранговой корреляции Спирмена для каждой меры близости, используя известную экспертную оценку (колонка `Score` в выборке).  \n",
        "\n",
        "_Введите коэффициент ранговой корреляции Спирмена для оценок, полученных методом `path_similarity` и известных экспертных оценок. Десятичный разделитель точка. Ответ округлите до тысячных:_\n",
        "```\n",
        "0.614\n",
        "```\n",
        "_Введите коэффициент ранговой корреляции Спирмена для оценок, полученных методом `lch_similarity` и известных экспертных оценок.\n",
        "Десятичный разделитель точка. Ответ округлите до тысячных:_\n",
        "```\n",
        "0.614\n",
        "```\n",
        "_Введите коэффициент ранговой корреляции Спирмена для оценок, полученных методом `wup_similarity` и известных экспертных оценок. Десятичный разделитель точка. Ответ округлите до тысячных:_\n",
        "```\n",
        "0.625\n",
        "```\n",
        "_При помощи метода `hyponyms()` найдите количество гипонимов для синсета `furnace.n.01`, а также при помощи метода `name()` найдите значение первого в гипонима из списка. Введите количество гипонимов для синсета `furnace.n.01`. Введите целое число:_\n",
        "```\n",
        "14\n",
        "```\n",
        "_Первый элемент списка гипонимов синсета `furnace.n.01`:\n",
        "Введите (без кавычек) результат выполнения метода `name()`, например `bird.n.01`:_\n",
        "```\n",
        "athanor.n.01\n",
        "```\n"
      ],
      "metadata": {
        "id": "d5XrU5VuK74N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "S47YnLX8L4lS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/Task_4_sample_9.csv\")\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnsxxqJ9J4ru",
        "outputId": "f3b3733b-1a72-433f-b9f3-c95d195e74bf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          word_1        word_2  Score\n",
            "0          space     chemistry   4.88\n",
            "1           five         month   3.38\n",
            "2           word    similarity   4.75\n",
            "3           king       cabbage   0.23\n",
            "4          tiger     carnivore   7.08\n",
            "..           ...           ...    ...\n",
            "145        train           car   6.31\n",
            "146       street        avenue   8.88\n",
            "147  observation  architecture   4.38\n",
            "148     ministry       culture   4.69\n",
            "149        peace          plan   4.75\n",
            "\n",
            "[150 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_sim_list, lch_sim_list, wup_sim_list, true_list = [], [], [], []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    w_1, w_2 = row['word_1'], row['word_2']\n",
        "    syn_1 = wn.synsets(w_1, pos='n')\n",
        "    syn_2 = wn.synsets(w_2, pos='n')\n",
        "    path_sim = max((s_1.path_similarity(s_2) or 0 for s_1 in syn_1 for s_2 in syn_2))\n",
        "    lch_sim = max((s_1.lch_similarity(s_2) or 0 for s_1 in syn_1 for s_2 in syn_2))\n",
        "    wup_sim = max((s_1.wup_similarity(s_2) or 0 for s_1 in syn_1 for s_2 in syn_2))\n",
        "    path_sim_list.append(path_sim)\n",
        "    lch_sim_list.append(lch_sim)\n",
        "    wup_sim_list.append(wup_sim)\n",
        "    true_list.append(row['Score'])\n",
        "\n",
        "# Вычислим корреляцию Спирмена\n",
        "path_corr = spearmanr(path_sim_list, true_list)[0]\n",
        "lch_corr = spearmanr(lch_sim_list, true_list)[0]\n",
        "wup_corr = spearmanr(wup_sim_list, true_list)[0]\n",
        "\n",
        "# Найдем гипонимы\n",
        "furnace = wn.synset('furnace.n.01')\n",
        "hyponyms = furnace.hyponyms()\n",
        "num_hyponyms = len(hyponyms)\n",
        "first_hyponym = hyponyms[0].name()\n",
        "\n",
        "print(\"Коэффициент ранговой корреляции Спирмена для path_similarity:\", round(path_corr, 3))\n",
        "print(\"Коэффициент ранговой корреляции Спирмена для lch_similarity:\", round(lch_corr, 3))\n",
        "print(\"Коэффициент ранговой корреляции Спирмена для wup_similarity:\", round(wup_corr, 3))\n",
        "print(\"Количество гипонимов для синсета furnace.n.01:\", num_hyponyms)\n",
        "print(\"Первый элемент списка гипонимов синсета furnace.n.01:\", first_hyponym)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbH805amD3ek",
        "outputId": "8efdbebd-b9ca-4e30-d953-3b498ec4fc57"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Коэффициент ранговой корреляции Спирмена для path_similarity: 0.614\n",
            "Коэффициент ранговой корреляции Спирмена для lch_similarity: 0.614\n",
            "Коэффициент ранговой корреляции Спирмена для wup_similarity: 0.625\n",
            "Количество гипонимов для синсета furnace.n.01: 14\n",
            "Первый элемент списка гипонимов синсета furnace.n.01: athanor.n.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DTWAGCv5D3pU"
      },
      "execution_count": 7,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}